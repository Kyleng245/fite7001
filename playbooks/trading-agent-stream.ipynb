{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 2 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5\n",
      "  Device 1: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from ../model/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  241 tensors\n",
      "llama_model_loader: - type q6_K:   41 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.14 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: system memory used  =  107.56 MiB\n",
      "llm_load_tensors: VRAM used           = 8694.21 MiB\n",
      "llm_load_tensors: offloading 40 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 41/41 layers to GPU\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4092\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 3196.88 MiB, K (f16): 1598.44 MiB, V (f16): 1598.44 MiB\n",
      "llama_build_graph: non-view tensors processed: 844/844\n",
      "llama_new_context_with_model: compute buffer total size = 2861.86 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 2858.67 MiB\n",
      "llama_new_context_with_model: total VRAM used: 11552.88 MiB (model: 8694.21 MiB, context: 2858.67 MiB)\n"
     ]
    }
   ],
   "source": [
    "# import langchain and llamacpp\n",
    "# llama cpp is a C++ interface that enables LLM to run locally with GPU support\n",
    "# we should initialize a llamacpp instance first and later langchain provides a wrapper for it\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"../model/llama-2-13b-chat.Q5_K_M.gguf\",\n",
    "    n_ctx=4092, # context of token size\n",
    "    n_gpu_layers=-1, #setting -1 to offload all the LLM layers to all available gpu \n",
    "    n_batch=4096, # no. of token in a prompt fed in LLM each time in a batch\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    verbose=False,\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    echo=True,\n",
    "    max_tokens=2048 # max tokens LLM could generate/answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''<s>[INST] <<SYS>>\n",
    "Assistant is a expert JSON builder designed to assist with a wide range of tasks.\n",
    "\n",
    "Assistant is able to trigger actions for User by responding with JSON strings that contain \"action\" and \"action_input\" parameters.\n",
    "\n",
    "Actions available to Assistant are:\n",
    "\n",
    "- \"StockExecutionTool\": Useful for when you need to execute stock trading orders for users.\n",
    "  - To use the StockExecutionTool tool, Assistant should write like so:\n",
    "    ```json\n",
    "    {{\"action\": \"StockExecutionTool\",\n",
    "      \"action_input\": \"('symbol', 'side', 'quantity')\"}}\n",
    "    ```\n",
    "  * `symbol` is the string of stock symbol for trading\n",
    "  * `side` should be enum of string where \"buy\" to buy the stork or \"sell\" to sell the stock\n",
    "  * `quantity` is the float number of quantity of stock to trade\n",
    "- \"ViewAccountTool\": Useful for when you need to query the trading account status such as buying power, and Profit and Loss\n",
    "  - To use the ViewAccountTool tool, Assistant should write like so:\n",
    "    ```json\n",
    "    {{\"action\": \"ViewAccountTool\",\n",
    "      \"action_input\": 'view_action'}}\n",
    "    * the view_action is an enum of string where it could be 'buying_power' if you want to view the buying power of the account or 'PnL' if you want to view the Profit or Loss\n",
    "    ```\n",
    "- \"ViewPositionTool\": Useful for when you need to query the position of individual stocks or all the stocks\n",
    "  - To use the ViewAccountTool tool, Assistant should write like so:\n",
    "    ```json\n",
    "    {{\"action\": \"ViewPositionTool\",\n",
    "      \"action_input\": 'symbol'}}\n",
    "  * `symbol` is the string of stock symbol to view the position, in case the user want to query all the position, please return \"ALL_STOCK\" as symbol \n",
    "    ```\n",
    "\n",
    "Here are some sample conversations between the Assistant and User:\n",
    "\n",
    "User: Hey how are you today?\n",
    "Assistant: ```json\n",
    "{{\"action\": \"Final Answer\",\n",
    " \"action_input\": \"I'm good thanks, how are you?\"}}\n",
    "```\n",
    "User: I'm great, could you help buy 1 Apple Stock?\n",
    "Assistant: ```json\n",
    "{{\"action\": \"StockExecutionTool\",\n",
    " \"action_input\": \"('AAPL', 'buy', '1')\"}}\n",
    "```\n",
    "User: Could I view my buying power of my trading account?\n",
    "Assistant: ```json\n",
    "{{\"action\": \"ViewAccountTool\",\n",
    " \"action_input\": \"buying_power\"}}\n",
    "```\n",
    "\n",
    "User: I want to know the profit and loss of my account\n",
    "Assistant: ```json\n",
    "{{\"action\": \"ViewAccountTool\",\n",
    " \"action_input\": \"PnL\"}}\n",
    "```\n",
    "\n",
    "You are only allowed to return ```json {{\"action\": ..., \"action_input\"}} ``` .\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "{0}[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config=dotenv_values(\"../.env\")\n",
    "\n",
    "trading_client = TradingClient(config['ALPACA_API_KEY'], config['ALPACA_SECRET_KEY'])\n",
    "\n",
    "def execute_order(symbol, side, quantity):\n",
    "    \"\"\"Execute stock trading orders based on the stock symbol, position side, and quantity\"\"\"\n",
    "\n",
    "    # preparing market order\n",
    "    market_order_data = MarketOrderRequest(\n",
    "                        symbol=symbol,\n",
    "                        qty=quantity,\n",
    "                        side=side,\n",
    "                        time_in_force=TimeInForce.DAY\n",
    "                        )\n",
    "    # Market order\n",
    "    market_order = trading_client.submit_order(\n",
    "                    order_data=market_order_data\n",
    "                )\n",
    "    return {\"order_id\": market_order.client_order_id, \"order_status\": market_order.status}\n",
    "\n",
    "def view_account_status(info_type):\n",
    "    account = trading_client.get_account()\n",
    "    if info_type == 'buying_power':\n",
    "        return {'response': f'${account.buying_power} is available as buying power.' }\n",
    "    if info_type == 'PnL':\n",
    "        balance_change = float(account.equity) - float(account.last_equity)\n",
    "        return {'response': f'Today\\'s portfolio balance change: ${balance_change}' }\n",
    "def get_position(symbol):\n",
    "    if symbol == \"ALL_STOCK\":\n",
    "        portfolio = trading_client.get_all_positions()\n",
    "        # Print the quantity of shares for each position.\n",
    "        positions = {}\n",
    "        for position in portfolio:\n",
    "            position = json.loads(position.model_dump_json())\n",
    "            positions[position['symbol']] = {key: position[key] for key in ['qty', 'side', 'cost_basis', 'market_value']}\n",
    "        return {\"response\": positions}\n",
    "    else:\n",
    "        position = json.loads(trading_client.get_open_position(symbol).model_dump_json())\n",
    "        selected_attributes = {key: position[key] for key in ['symbol', 'qty', 'side', 'cost_basis', 'market_value']}\n",
    "        return {\"response\": selected_attributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_command(command):\n",
    "    # Put user command into prompt (in future projects we'll be re-injecting whole chat history here)\n",
    "    prompt = prompt_template.format(\"User: \" + command)\n",
    "    \n",
    "    # Send command to the model\n",
    "    # Assuming `llm.invoke` is a placeholder for sending command to an LLM (Language Learning Model)\n",
    "    # and getting a response back\n",
    "    output = llm.invoke(prompt, stop=[\"User:\"])\n",
    "    response = output\n",
    "    \n",
    "    # Yielding the initial response\n",
    "    for token in response.split():\n",
    "        yield token\n",
    "    \n",
    "    # Initialize result outside of try-except block\n",
    "    result = None\n",
    "    \n",
    "    # Try to process the response and perform actions\n",
    "    try:\n",
    "        # Extract json from model response by finding first and last brackets {}\n",
    "        firstBracketIndex = response.index(\"{\")\n",
    "        lastBracketIndex = len(response) - response[::-1].index(\"}\")\n",
    "        jsonString = response[firstBracketIndex:lastBracketIndex]\n",
    "        responseJson = json.loads(jsonString)\n",
    "        \n",
    "        if responseJson['action'] == 'StockExecutionTool':\n",
    "            action_input = eval(responseJson['action_input'])\n",
    "            result = execute_order(action_input[0], action_input[1], float(action_input[2]))\n",
    "        elif responseJson['action'] == 'ViewAccountTool':\n",
    "            action_input = responseJson['action_input']\n",
    "            result = view_account_status(action_input)\n",
    "        elif responseJson['action'] == 'ViewPositionTool':\n",
    "            action_input = responseJson['action_input']\n",
    "            result = get_position(action_input)\n",
    "            \n",
    "        # If result was computed, yield it\n",
    "        if result:\n",
    "            final_response = str(result)\n",
    "            for token in final_response.split():\n",
    "                yield token\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        final_response = str({\"response\": \"The action is not triggered. Please try again.\"})\n",
    "        for token in final_response.split():\n",
    "            yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Sure! Here's my response:\n",
      "\n",
      "```json\n",
      "{\"action\": \"StockExecutionTool\",\n",
      " \"action_input\": \"('AAPL', 'buy', '10')\"}\n",
      "```Sure!\n",
      "Here's\n",
      "my\n",
      "response:\n",
      "```json\n",
      "{\"action\":\n",
      "\"StockExecutionTool\",\n",
      "\"action_input\":\n",
      "\"('AAPL',\n",
      "'buy',\n",
      "'10')\"}\n",
      "```\n",
      "{'order_id':\n",
      "'9a03a0de-c4d8-4e06-b556-e886dae8b5f4',\n",
      "'order_status':\n",
      "<OrderStatus.ACCEPTED:\n",
      "'accepted'>}\n"
     ]
    }
   ],
   "source": [
    "result = process_command(\"Hi, could you help me buy 10 Apple stocks?\")\n",
    "import time\n",
    "print()\n",
    "for token in result:\n",
    "    time.sleep(0.3)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Assistant: ```json\n",
      "{\"action\": \"ViewAccountTool\",\n",
      " \"action_input\": \"buying_power\"}\n",
      "```Assistant:\n",
      "```json\n",
      "{\"action\":\n",
      "\"ViewAccountTool\",\n",
      "\"action_input\":\n",
      "\"buying_power\"}\n",
      "```\n",
      "{'response':\n",
      "'$135948.91\n",
      "is\n",
      "available\n",
      "as\n",
      "buying\n",
      "power.'}\n"
     ]
    }
   ],
   "source": [
    "result = process_command(\"What is my buying power now?\")\n",
    "import time\n",
    "print()\n",
    "for token in result:\n",
    "    time.sleep(0.3)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fite7001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
